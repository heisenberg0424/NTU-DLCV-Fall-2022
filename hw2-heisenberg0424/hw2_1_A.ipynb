{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe0f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9d01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2_1 import *\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.utils as vutils\n",
    "import sys\n",
    "import subprocess\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51696dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.99\n",
    "epochs = 500\n",
    "manualSeed = 999\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "test_noise = torch.randn(1000, 100, 1, 1, device='cuda')\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device='cuda')\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()\n",
    "\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "dataloader = loadData('hw2_data/face/train/',batch_size,12)\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(),lr=lr,betas=(b1,b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(),lr=lr,betas=(b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f86580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val():\n",
    "    generator.eval().cuda()\n",
    "    with torch.no_grad():\n",
    "        test_noise = torch.randn(1000,100,1,1,device='cuda')\n",
    "        test_img = generator(test_noise).detach().cpu()\n",
    "    \n",
    "    for i in range(1000):\n",
    "        save_image(test_img[i],'p1_result/'+str(i)+'.png')\n",
    "    \n",
    "    FID = subprocess.run([sys.executable,'-m','pytorch_fid','p1_result/','hw2_data/face/val','--device', 'cuda:0'],capture_output=True)\n",
    "    FACE = subprocess.run([sys.executable,'face_recog.py','--image_dir','p1_result/'],capture_output=True)\n",
    "    print(FID.stdout.decode(),end='')\n",
    "    print(FACE.stdout.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8602aaae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfe70704fac445dabeae3f187300bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "FID:  309.62697996486867\n",
      "Face recognition Accuracy: 0.000%\n",
      "\n",
      "Epoch: 10\n",
      "FID:  146.16184072924014\n",
      "Face recognition Accuracy: 70.529%\n",
      "\n",
      "Epoch: 20\n",
      "FID:  73.27982974106644\n",
      "Face recognition Accuracy: 79.221%\n",
      "\n",
      "Epoch: 30\n",
      "FID:  61.826490553099575\n",
      "Face recognition Accuracy: 76.823%\n",
      "\n",
      "Epoch: 40\n",
      "FID:  61.33405203608709\n",
      "Face recognition Accuracy: 75.724%\n",
      "\n",
      "Epoch: 50\n",
      "FID:  58.22679633396751\n",
      "Face recognition Accuracy: 73.726%\n",
      "\n",
      "Epoch: 60\n",
      "FID:  49.03276535301998\n",
      "Face recognition Accuracy: 79.720%\n",
      "\n",
      "Epoch: 70\n",
      "FID:  46.313287387289165\n",
      "Face recognition Accuracy: 72.228%\n",
      "\n",
      "Epoch: 80\n",
      "FID:  51.622824993863105\n",
      "Face recognition Accuracy: 78.921%\n",
      "\n",
      "Epoch: 90\n",
      "FID:  49.082999859381346\n",
      "Face recognition Accuracy: 78.921%\n",
      "\n",
      "Epoch: 100\n",
      "FID:  45.96276945387129\n",
      "Face recognition Accuracy: 78.521%\n",
      "\n",
      "Epoch: 110\n",
      "FID:  54.71483157492298\n",
      "Face recognition Accuracy: 74.326%\n",
      "\n",
      "Epoch: 120\n",
      "FID:  50.28735067018428\n",
      "Face recognition Accuracy: 79.021%\n",
      "\n",
      "Epoch: 130\n",
      "FID:  48.79463309846187\n",
      "Face recognition Accuracy: 74.525%\n",
      "\n",
      "Epoch: 140\n",
      "FID:  49.72996904779839\n",
      "Face recognition Accuracy: 78.721%\n",
      "\n",
      "Epoch: 150\n",
      "FID:  48.25387647734752\n",
      "Face recognition Accuracy: 74.725%\n",
      "\n",
      "Epoch: 160\n",
      "FID:  61.85867428418044\n",
      "Face recognition Accuracy: 72.727%\n",
      "\n",
      "Epoch: 170\n",
      "FID:  52.158124994078605\n",
      "Face recognition Accuracy: 80.320%\n",
      "\n",
      "Epoch: 180\n",
      "FID:  51.61755979830531\n",
      "Face recognition Accuracy: 76.523%\n",
      "\n",
      "Epoch: 190\n",
      "FID:  49.04333707634041\n",
      "Face recognition Accuracy: 73.327%\n",
      "\n",
      "Epoch: 200\n",
      "FID:  50.79571855122521\n",
      "Face recognition Accuracy: 79.221%\n",
      "\n",
      "Epoch: 210\n",
      "FID:  53.56113778766516\n",
      "Face recognition Accuracy: 77.123%\n",
      "\n",
      "Epoch: 220\n",
      "FID:  63.932441346209174\n",
      "Face recognition Accuracy: 68.032%\n",
      "\n",
      "Epoch: 230\n",
      "FID:  50.1700862333808\n",
      "Face recognition Accuracy: 78.721%\n",
      "\n",
      "Epoch: 240\n",
      "FID:  47.74415612368105\n",
      "Face recognition Accuracy: 76.024%\n",
      "\n",
      "Epoch: 250\n",
      "FID:  50.03371540897251\n",
      "Face recognition Accuracy: 74.326%\n",
      "\n",
      "Epoch: 260\n",
      "FID:  45.107238401542986\n",
      "Face recognition Accuracy: 75.824%\n",
      "\n",
      "Epoch: 270\n",
      "FID:  46.12742878488359\n",
      "Face recognition Accuracy: 81.419%\n",
      "\n",
      "Epoch: 280\n",
      "FID:  48.77261994124271\n",
      "Face recognition Accuracy: 78.422%\n",
      "\n",
      "Epoch: 290\n",
      "FID:  53.00838052472753\n",
      "Face recognition Accuracy: 72.727%\n",
      "\n",
      "Epoch: 300\n",
      "FID:  58.54058677408841\n",
      "Face recognition Accuracy: 77.822%\n",
      "\n",
      "Epoch: 310\n",
      "FID:  57.0361417343899\n",
      "Face recognition Accuracy: 76.124%\n",
      "\n",
      "Epoch: 320\n",
      "FID:  50.70007458702935\n",
      "Face recognition Accuracy: 77.922%\n",
      "\n",
      "Epoch: 330\n",
      "FID:  49.77307922526643\n",
      "Face recognition Accuracy: 77.922%\n",
      "\n",
      "Epoch: 340\n",
      "FID:  42.02804221435852\n",
      "Face recognition Accuracy: 78.821%\n",
      "\n",
      "Epoch: 350\n",
      "FID:  55.14636298853583\n",
      "Face recognition Accuracy: 77.223%\n",
      "\n",
      "Epoch: 360\n",
      "FID:  48.61210696685072\n",
      "Face recognition Accuracy: 75.425%\n",
      "\n",
      "Epoch: 370\n",
      "FID:  49.937978807096215\n",
      "Face recognition Accuracy: 78.322%\n",
      "\n",
      "Epoch: 380\n",
      "FID:  51.80362702559589\n",
      "Face recognition Accuracy: 74.725%\n",
      "\n",
      "Epoch: 390\n",
      "FID:  47.04105534474772\n",
      "Face recognition Accuracy: 78.721%\n",
      "\n",
      "Epoch: 400\n",
      "FID:  50.516373128881014\n",
      "Face recognition Accuracy: 82.218%\n",
      "\n",
      "Epoch: 410\n",
      "FID:  47.42393350525893\n",
      "Face recognition Accuracy: 79.021%\n",
      "\n",
      "Epoch: 420\n",
      "FID:  51.947815019790795\n",
      "Face recognition Accuracy: 77.622%\n",
      "\n",
      "Epoch: 430\n",
      "FID:  48.339685012103104\n",
      "Face recognition Accuracy: 77.023%\n",
      "\n",
      "Epoch: 440\n",
      "FID:  53.33771908921827\n",
      "Face recognition Accuracy: 74.026%\n",
      "\n",
      "Epoch: 450\n",
      "FID:  55.81784667087845\n",
      "Face recognition Accuracy: 72.727%\n",
      "\n",
      "Epoch: 460\n",
      "FID:  52.584075402744105\n",
      "Face recognition Accuracy: 75.125%\n",
      "\n",
      "Epoch: 470\n",
      "FID:  54.273199501177515\n",
      "Face recognition Accuracy: 76.923%\n",
      "\n",
      "Epoch: 480\n",
      "FID:  48.99214960688937\n",
      "Face recognition Accuracy: 74.825%\n",
      "\n",
      "Epoch: 490\n",
      "FID:  46.247541692024924\n",
      "Face recognition Accuracy: 78.921%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_list = []\n",
    "G_loss = []\n",
    "D_loss = []\n",
    "iters = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i ,data in enumerate(dataloader,0):\n",
    "        data = data.cuda()\n",
    "        optimizer_D.zero_grad()\n",
    "        label = torch.full((data.shape[0],), 1.0, dtype=torch.float, device='cuda')\n",
    "        #label += 0.1 * torch.randn((data.shape[0],),device='cuda')\n",
    "        output = discriminator(data).view(-1)\n",
    "        real_loss = criterion(output,label)\n",
    "        real_loss.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        noise = torch.randn(data.shape[0],100,1,1,device='cuda')\n",
    "        fake = generator(noise)\n",
    "        label.fill_(0.0)\n",
    "        #label += 0.1 * torch.randn((data.shape[0],),device='cuda')\n",
    "        output = discriminator(fake.detach()).view(-1)\n",
    "        fake_loss = criterion(output,label)\n",
    "        fake_loss.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        \n",
    "        d_loss = real_loss + fake_loss\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        label.fill_(1.0)\n",
    "        output = discriminator(fake).view(-1)\n",
    "        g_loss = criterion(output,label)\n",
    "        g_loss.backward()\n",
    "        \n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "#         if i % 50 == 0:\n",
    "#             print('[%3d/%3d][%3d/%3d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "#                   % (epoch, epochs, i, len(dataloader),\n",
    "#                      d_loss.item(), g_loss.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "        G_loss.append(g_loss.item())\n",
    "        D_loss.append(d_loss.item())\n",
    "        \n",
    "#         if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(dataloader)-1)):\n",
    "#             with torch.no_grad():\n",
    "#                 fake = generator(fixed_noise).detach().cpu()\n",
    "#             img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "#             save_image(fake.data[:25], \"p1_result/%d.png\" % iters, nrow=5, normalize=True)\n",
    "        iters += 1\n",
    "    if(epoch%10==0):\n",
    "        print(\"Epoch:\",epoch)\n",
    "        val()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3d37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fake = generator(test_noise).detach().cpu()\n",
    "    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "    save_image(fake.data[:32], \"p1_1.png\" , nrow=8, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c97dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(generator)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aed043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8 (DLCVenv)",
   "language": "python",
   "name": "dlcvenc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
